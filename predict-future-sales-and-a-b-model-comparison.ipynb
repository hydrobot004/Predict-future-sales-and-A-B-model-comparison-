{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Notebook code was buggy ðŸ‘¾, I was able to identify the coding issues ðŸ‘½ and replaced some lines of code for full functionality. ðŸ¤–\n# Any ideas for running a comparison between submission_predict_1 and submission_predict_2 would be appreciated.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-28T19:45:37.194187Z","iopub.execute_input":"2022-11-28T19:45:37.194946Z","iopub.status.idle":"2022-11-28T19:45:37.230766Z","shell.execute_reply.started":"2022-11-28T19:45:37.194834Z","shell.execute_reply":"2022-11-28T19:45:37.229574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport matplotlib.gridspec as gridspec\nfrom termcolor import colored\nimport gc,time,os\n\n\nplt.style.use('seaborn-whitegrid')\nimport warnings\nwarnings.simplefilter(\"ignore\")\npd.set_option('display.float_format', lambda x: '%.2f' % x)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:45:37.232672Z","iopub.execute_input":"2022-11-28T19:45:37.233025Z","iopub.status.idle":"2022-11-28T19:45:38.368058Z","shell.execute_reply.started":"2022-11-28T19:45:37.232978Z","shell.execute_reply":"2022-11-28T19:45:38.366701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. train.csv -> showing the price of the item and the number of items sold on each date.\n\n2. shop.csv -> Details of shops corresponding to the shop id in train.csv.\n\n3. item.csv -> Details of items corresponding to item id in train.csv\n\n4. item_categories.csv -> Details of item category corresponding to category ID in item.csv\n\n5. test.csv -> test data for prediction","metadata":{}},{"cell_type":"markdown","source":"train.csv\n--------\n\n- date: date in format dd/mm/yy.\n- date_block_num: a consecutive month number, used for convenience. January 2013 is 0, February 2013 is 1 and so on.\n- shop_id: unique identifier of a shop.\n- item_id: unique identifier of a product.\n- item_price: current price of an item.\n- item_cnt_day: number of products sold. We are predicting a monthly amount of this measure.\n\n\nshop.csv\n--------\n- shop_name: shop name corresponding to shop id in train.csv\n- shop_id\n\nitem.csv\n--------\n- item_name: item name corresponding to item id in train.csv\n- item_id\n- item_category_id: category id of item\n\n\nitem_category.csv\n-----------------\n- item_category_name: category name of item cooresponding to item_category_id in item.csv \n- category_id\n\ntest.csv\n----------\n- ID - an Id that represents a (Shop, Item) tuple within the test set\n- shop_id\n- item_id","metadata":{}},{"cell_type":"code","source":"TRAIN_SALES_CSV = '../input/english-converted-datasets/sales_train.csv'\nSHOPS_CSV = '../input/english-converted-datasets/shops.csv'\nITEMS_CSV= '../input/english-converted-datasets/items.csv'\nITEM_CATEGORY_CSV = '../input/english-converted-datasets/item_categories.csv'\nTEST_CSV ='../input/english-converted-datasets/test.csv'","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:45:38.369795Z","iopub.execute_input":"2022-11-28T19:45:38.370582Z","iopub.status.idle":"2022-11-28T19:45:38.375617Z","shell.execute_reply.started":"2022-11-28T19:45:38.370511Z","shell.execute_reply":"2022-11-28T19:45:38.374814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_data(df_train,heading='TRAIN DATA'):\n    \n    \"\"\"\n    function which gives basic data information\n    Args:\n        df_train: pandas dataframe\n        heading: deading to display\n    Returns:\n        None\n    \"\"\"\n\n    print(colored(heading,'red'))\n    print('')\n    print('Date shape')\n    print(f'shape:{df_train.shape}')\n    print('')\n    print('--'*50)\n    print('')\n    print('Sample:')\n    print(df_train.head(3).to_markdown())\n    print('')\n    print('--'*50)\n    print('')\n    print('Columns and data types:')\n    print('')\n    print(df_train.info())","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:45:38.377824Z","iopub.execute_input":"2022-11-28T19:45:38.378932Z","iopub.status.idle":"2022-11-28T19:45:38.390138Z","shell.execute_reply.started":"2022-11-28T19:45:38.378883Z","shell.execute_reply":"2022-11-28T19:45:38.388636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(TRAIN_SALES_CSV)\ndf_shop = pd.read_csv(SHOPS_CSV)\ndf_item = pd.read_csv(ITEMS_CSV)\ndf_itemcat = pd.read_csv(ITEM_CATEGORY_CSV)\n\n# include some fancy print formatting ðŸ¤“\n\nshow_data(df_train,heading='TRAIN DATA')\nprint('')\nprint('__'*40)\nprint('')\nshow_data(df_shop,heading='SHOP DATA')\nprint('')\nprint('__'*40)\nprint('')\nshow_data(df_item,heading='ITEM DETAILS DATA')\nprint('__'*40)\nprint('')\nshow_data(df_itemcat,heading='ITEM CATEGORY DATA')","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:45:38.391779Z","iopub.execute_input":"2022-11-28T19:45:38.392308Z","iopub.status.idle":"2022-11-28T19:45:41.172281Z","shell.execute_reply.started":"2022-11-28T19:45:38.392257Z","shell.execute_reply":"2022-11-28T19:45:41.171271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(TEST_CSV)\nshow_data(df_test,heading='TEST DATA')","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:45:41.173562Z","iopub.execute_input":"2022-11-28T19:45:41.173806Z","iopub.status.idle":"2022-11-28T19:45:41.316772Z","shell.execute_reply.started":"2022-11-28T19:45:41.173776Z","shell.execute_reply":"2022-11-28T19:45:41.316021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation:** \nAs mentioned before for test data, we only have shop id and item id. The train data is spread over 4 files. From the examples above, we know that there are common identifiers across multiple files. It will be great moving forward once we merge these train files based on a common ID.","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(TEST_CSV)\nshow_data(df_test,heading='TEST DATA')","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:45:41.317703Z","iopub.execute_input":"2022-11-28T19:45:41.317924Z","iopub.status.idle":"2022-11-28T19:45:41.387796Z","shell.execute_reply.started":"2022-11-28T19:45:41.317898Z","shell.execute_reply":"2022-11-28T19:45:41.386847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Merging all dataframes together\ndff = df_train.merge(df_item,on=\"item_id\")  # <-- this is a code fix so the notebook can properly function\n#dff = dff.merge(df_itemcat,on=\"item_category_id\")  # doesn't work properly removed\ndff = dff.merge(df_shop,on=\"shop_id\")\ndff = dff.drop(columns=[\"item_name\"])\ndff.to_csv('merged_original.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:45:41.389564Z","iopub.execute_input":"2022-11-28T19:45:41.389933Z","iopub.status.idle":"2022-11-28T19:45:53.156617Z","shell.execute_reply.started":"2022-11-28T19:45:41.389885Z","shell.execute_reply":"2022-11-28T19:45:53.155382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = dff.copy()\n# df.to_csv('merged_original.csv',index=False)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:45:53.158127Z","iopub.execute_input":"2022-11-28T19:45:53.158511Z","iopub.status.idle":"2022-11-28T19:45:53.353576Z","shell.execute_reply.started":"2022-11-28T19:45:53.158465Z","shell.execute_reply":"2022-11-28T19:45:53.352704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Statistical Description of Dataframe","metadata":{}},{"cell_type":"code","source":"df.describe()\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:45:53.358522Z","iopub.execute_input":"2022-11-28T19:45:53.359104Z","iopub.status.idle":"2022-11-28T19:45:53.871561Z","shell.execute_reply.started":"2022-11-28T19:45:53.359061Z","shell.execute_reply":"2022-11-28T19:45:53.870522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Timeframe of Dataset","metadata":{}},{"cell_type":"code","source":"df[\"date\"]=  pd.to_datetime(df[\"date\"], format='%d.%m.%Y')\ndf.sort_values(by=\"date\", ascending=True, inplace=True)\nprint(f'Minimum data present: {df[\"date\"].min()}')\nprint(f'Maximum date present: {df[\"date\"].max()}')","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:45:53.873125Z","iopub.execute_input":"2022-11-28T19:45:53.873464Z","iopub.status.idle":"2022-11-28T19:45:55.422290Z","shell.execute_reply.started":"2022-11-28T19:45:53.873423Z","shell.execute_reply":"2022-11-28T19:45:55.421179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sorting dataframe based on date\ndf = df.sort_values(by='date').reset_index(drop=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:45:55.424176Z","iopub.execute_input":"2022-11-28T19:45:55.424538Z","iopub.status.idle":"2022-11-28T19:45:55.953746Z","shell.execute_reply.started":"2022-11-28T19:45:55.424489Z","shell.execute_reply":"2022-11-28T19:45:55.952585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,axes = plt.subplots(1,2,figsize=(15,5))\nsns.boxplot(df['item_cnt_day'],ax=axes[0])\naxes[0].set_title('Boxplot')\nsns.distplot(df['item_cnt_day'],ax=axes[1])\naxes[1].set_title('Distribution')\nplt.suptitle('No of units sold(Item Cnt day)',fontsize=\"20\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:45:55.955241Z","iopub.execute_input":"2022-11-28T19:45:55.955668Z","iopub.status.idle":"2022-11-28T19:46:07.032027Z","shell.execute_reply.started":"2022-11-28T19:45:55.955618Z","shell.execute_reply":"2022-11-28T19:46:07.031069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['item_cnt_day'].describe()\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:46:07.033295Z","iopub.execute_input":"2022-11-28T19:46:07.033577Z","iopub.status.idle":"2022-11-28T19:46:07.112890Z","shell.execute_reply.started":"2022-11-28T19:46:07.033544Z","shell.execute_reply":"2022-11-28T19:46:07.111640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Minimum value {df[\"item_cnt_day\"].min()}')\nprint(f'Maximum value {df[\"item_cnt_day\"].max()}')","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:46:07.114506Z","iopub.execute_input":"2022-11-28T19:46:07.114881Z","iopub.status.idle":"2022-11-28T19:46:07.130253Z","shell.execute_reply.started":"2022-11-28T19:46:07.114832Z","shell.execute_reply":"2022-11-28T19:46:07.129238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let us print percentile values\nfor i in range(0,101,10):\n    print(f'{i}th percentile value for item_cnt_day is {np.percentile(df[\"item_cnt_day\"],i)}')\n    \nprint('--'*50)\n\nfor i in range(90,100):\n    print(f'{i}th percentile value for item_cnt_day is {np.percentile(df[\"item_cnt_day\"],i)}')\n    \nprint('--'*50)\n\nfor i in range(1,10):\n    k = 99 + i/10 \n    print(f'{k}th percentile value for item_cnt_day is {np.percentile(df[\"item_cnt_day\"],k)}')","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:46:07.131516Z","iopub.execute_input":"2022-11-28T19:46:07.131841Z","iopub.status.idle":"2022-11-28T19:46:07.825894Z","shell.execute_reply.started":"2022-11-28T19:46:07.131799Z","shell.execute_reply":"2022-11-28T19:46:07.823768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we will remove some extreme outliers\ndf[df['item_cnt_day'] > df['item_cnt_day'].quantile(0.95)]","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:46:07.827573Z","iopub.execute_input":"2022-11-28T19:46:07.827883Z","iopub.status.idle":"2022-11-28T19:46:07.906949Z","shell.execute_reply.started":"2022-11-28T19:46:07.827849Z","shell.execute_reply":"2022-11-28T19:46:07.905871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Identify less than zero item count perday, will be removed","metadata":{}},{"cell_type":"code","source":"df[df['item_cnt_day'] < 0]\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:46:07.908564Z","iopub.execute_input":"2022-11-28T19:46:07.908895Z","iopub.status.idle":"2022-11-28T19:46:07.937322Z","shell.execute_reply.started":"2022-11-28T19:46:07.908854Z","shell.execute_reply":"2022-11-28T19:46:07.936402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'shape of data before outliers: {df.shape}')\ndf = df[df['item_cnt_day'] >= 0]\nupper_quantile = df['item_cnt_day'].quantile(0.95)\nprint(f'Removing values greater that upper_quantile {upper_quantile} and less than 0')\ndf['item_cnt_day'] = np.where(df['item_cnt_day'] > upper_quantile, upper_quantile, df['item_cnt_day'])\n\nprint(f'shape of data after removing outliers: {df.shape}')\nprint(f'Minimum units of product sold a time {df[\"item_cnt_day\"].min()}')\nprint(f'Maximum units of product sold a time {df[\"item_cnt_day\"].max()}')","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:46:07.938625Z","iopub.execute_input":"2022-11-28T19:46:07.938879Z","iopub.status.idle":"2022-11-28T19:46:08.186859Z","shell.execute_reply.started":"2022-11-28T19:46:07.938848Z","shell.execute_reply":"2022-11-28T19:46:08.185855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,axes = plt.subplots(1,2,figsize=(15,5))\nsns.boxplot(df['item_price'],ax=axes[0])\naxes[0].set_title('Boxplot')\nsns.distplot(df['item_price'],ax=axes[1])\naxes[1].set_title('Distribution')\nplt.suptitle('Item Price per unit',fontsize=\"20\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:46:08.188579Z","iopub.execute_input":"2022-11-28T19:46:08.188968Z","iopub.status.idle":"2022-11-28T19:46:19.201263Z","shell.execute_reply.started":"2022-11-28T19:46:08.188890Z","shell.execute_reply":"2022-11-28T19:46:19.200142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['item_price'].describe()\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:46:19.202458Z","iopub.execute_input":"2022-11-28T19:46:19.202717Z","iopub.status.idle":"2022-11-28T19:46:19.312608Z","shell.execute_reply.started":"2022-11-28T19:46:19.202686Z","shell.execute_reply":"2022-11-28T19:46:19.311665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let us print percentile values\nfor i in range(0,101,10):\n    print(f'{i}th percentile value for item_price is {np.percentile(df[\"item_price\"],i)}')\n    \nprint('--'*50)\n\nfor i in range(90,100):\n    print(f'{i}th percentile value for item_price is {np.percentile(df[\"item_price\"],i)}')\n    \nprint('--'*50)\n\nfor i in range(1,10):\n    k = 99 + i/10 \n    print(f'{k}th percentile value for item_price is {np.percentile(df[\"item_price\"],k)}')","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:46:19.313845Z","iopub.execute_input":"2022-11-28T19:46:19.314105Z","iopub.status.idle":"2022-11-28T19:46:20.220081Z","shell.execute_reply.started":"2022-11-28T19:46:19.314073Z","shell.execute_reply":"2022-11-28T19:46:20.219182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Removing Outliers","metadata":{}},{"cell_type":"code","source":"# we have an extreme outlier value in item price. Let us remove it\n\nprint(f'shape of data before removing outliers: {df.shape}')\ndf = df[df['item_price'] >= 0]\nupper_quantile = df['item_price'].quantile(0.95)\ndf['item_price'] = np.where(df['item_price'] > upper_quantile, upper_quantile, df['item_price'])\nprint(f'shape of data after removing outliers: {df.shape}')\n\nprint(f'Minimum price of a single item {df[\"item_price\"].min()}')\nprint(f'Maximum price ofa single item {df[\"item_price\"].max()}')","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:46:20.222281Z","iopub.execute_input":"2022-11-28T19:46:20.223131Z","iopub.status.idle":"2022-11-28T19:46:20.498323Z","shell.execute_reply.started":"2022-11-28T19:46:20.223081Z","shell.execute_reply":"2022-11-28T19:46:20.497377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tmp = df[df['shop_id'] == 31][['date','item_id','item_price']].reset_index(drop=True)\nitems = df_tmp['item_id'].unique()[0:8]\n\nfig,axes = plt.subplots(1,1,figsize=(25,8))\ncolors = ['red','orange','blue','green','yellow','purple','cyan','brown']\nfor i,item in enumerate(items):\n    dprice = df_tmp[df_tmp['item_id'] == item][['item_price','date']]\n    \n    sns.lineplot(x=dprice['date'],y=dprice['item_price'],ax=axes,color=colors[i],label=item)\n    \naxes.set_title('Price change of items - shop_id 31',fontsize=\"28\")\naxes.legend()\nplt.show()\n\n\ndf_tmp = df[df['shop_id'] == 28][['date','item_id','item_price']].reset_index(drop=True)\nitems = df_tmp['item_id'].unique()[0:8]\n\nfig,axes = plt.subplots(1,1,figsize=(25,8))\ncolors = ['red','orange','blue','green','yellow','purple','cyan','brown']\nfor i,item in enumerate(items):\n    dprice = df_tmp[df_tmp['item_id'] == item][['item_price','date']]\n    \n    sns.lineplot(x=dprice['date'],y=dprice['item_price'],ax=axes,color=colors[i],label=item)\n    \naxes.set_title('Price change of items - shop_id 28',fontsize=\"28\")\naxes.legend()\nplt.show()\n\n\n\ndf_tmp = df[df['shop_id'] == 21][['date','item_id','item_price']].reset_index(drop=True)\nitems = df_tmp['item_id'].unique()[0:8]\n\nfig,axes = plt.subplots(1,1,figsize=(25,8))\ncolors = ['red','orange','blue','green','yellow','purple','cyan','brown']\nfor i,item in enumerate(items):\n    dprice = df_tmp[df_tmp['item_id'] == item][['item_price','date']]\n    \n    sns.lineplot(x=dprice['date'],y=dprice['item_price'],ax=axes,color=colors[i],label=item)\n    \naxes.set_title('Price change of items - shop_id 21',fontsize=\"28\")\naxes.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:46:20.499569Z","iopub.execute_input":"2022-11-28T19:46:20.499811Z","iopub.status.idle":"2022-11-28T19:46:22.552732Z","shell.execute_reply.started":"2022-11-28T19:46:20.499781Z","shell.execute_reply":"2022-11-28T19:46:22.551763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Sales_per_item'] = df['item_cnt_day'] * df['item_price']\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:46:22.553862Z","iopub.execute_input":"2022-11-28T19:46:22.554081Z","iopub.status.idle":"2022-11-28T19:46:22.568773Z","shell.execute_reply.started":"2022-11-28T19:46:22.554054Z","shell.execute_reply":"2022-11-28T19:46:22.567889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(25,7))\ngs = fig.add_gridspec(1, 3)\nax00 = fig.add_subplot(gs[0,0])\nax01 = fig.add_subplot(gs[0,1])\nax02 = fig.add_subplot(gs[0,2])\n\n# setting size of xlabel and ylabel\n\nax00.tick_params(axis='both', labelsize=15)\nax01.tick_params(axis='both', labelsize=15)\nax02.tick_params(axis='both', labelsize=15)\nax00.set_title('Number of sales per item', fontsize=20)\nax01.set_title('Item price distribution', fontsize=20)\nax02.set_title('Item count distribution', fontsize=20)\nsns.histplot(data = df ,x=\"Sales_per_item\", kde=True, bins=50,ax=ax00, color=\"violet\")\nsns.histplot(data = df ,x=\"item_price\", kde=True, ax=ax01, bins=50, color=\"tomato\")\nsns.histplot(data = df ,x=\"item_cnt_day\", kde=False, ax=ax02, bins=20, color=\"cornflowerblue\")\n\nfig.subplots_adjust(top=0.8)\nfig.suptitle('Sales Feature Distributions per Day', fontsize=\"28\");","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:46:22.570290Z","iopub.execute_input":"2022-11-28T19:46:22.570764Z","iopub.status.idle":"2022-11-28T19:46:47.171639Z","shell.execute_reply.started":"2022-11-28T19:46:22.570714Z","shell.execute_reply":"2022-11-28T19:46:47.170883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_shop_ids = set(df['shop_id'].unique())\ntest_shop_ids = set(df_test['shop_id'].unique())\n\ntrain_item_ids = set(df['item_id'].unique())\ntest_item_ids = set(df_test['item_id'].unique())\n\nprint(f'There are about {len(train_shop_ids)} unique shop ids in train data and {len(test_shop_ids)} shop ids in test data')\nprint(f'There are about {len(train_item_ids)} unique item ids in train data and {len(test_item_ids)} item ids in test data')\nprint('--'*50)\n\ndf['pair'] = df[['shop_id','item_id']].apply(lambda x: str(x['shop_id'])+'_'+str(x['item_id']),axis=1)\ndf_test['pair'] = df_test[['shop_id','item_id']].apply(lambda x: str(x['shop_id'])+'_'+str(x['item_id']),axis=1)\ntrain_pair_ids = set(df['pair'].unique())\ntest_pair_ids = set(df_test['pair'].unique())\n\nprint(f'There are {len(train_shop_ids - test_shop_ids)} shop ids present in train data which are not in test data')\nprint(f'There are {len(train_item_ids - test_item_ids)} item ids present in train data which are not in test data')\nprint(f'There are {len(train_pair_ids - test_pair_ids)} shop id item id pairs present in train data which are not in test data')\n\nprint('--'*50)\n\nprint(f'There are {len(test_item_ids - train_item_ids)} item ids present in test data which are not in train data')\nprint(f'There are {len(test_shop_ids - train_shop_ids)} shop ids present in test data which are not in train data')\nprint(f'There are {len(test_pair_ids - train_pair_ids)} shop id item id pairs present in test data which are not in train data')","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:46:47.173076Z","iopub.execute_input":"2022-11-28T19:46:47.173633Z","iopub.status.idle":"2022-11-28T19:47:39.795096Z","shell.execute_reply.started":"2022-11-28T19:46:47.173589Z","shell.execute_reply":"2022-11-28T19:47:39.794034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Total number of unique shop ids: {df[\"shop_id\"].nunique()}')\ndf_tmp = df[[\"shop_id\",\"Sales_per_item\",\"item_cnt_day\"]]\ndf_tmp= pd.pivot_table(data=df_tmp,index=[\"shop_id\"],aggfunc={\"item_cnt_day\":np.sum,\"Sales_per_item\":np.sum}).reset_index()\n\n\nfig, axes = plt.subplots(2,1,figsize=(20,10))\nsns.barplot(x=df_tmp[\"shop_id\"],y=df_tmp[\"item_cnt_day\"],ax=axes[0])\naxes[0].set_title(\"Total number of units sold among various shops\")\nsns.barplot(x=df_tmp[\"shop_id\"],y=df_tmp[\"Sales_per_item\"],ax=axes[1])\naxes[1].set_title('Total turn over in various shops')\nplt.suptitle('Shop id', fontsize=\"28\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:47:39.799700Z","iopub.execute_input":"2022-11-28T19:47:39.800005Z","iopub.status.idle":"2022-11-28T19:47:41.704670Z","shell.execute_reply.started":"2022-11-28T19:47:39.799970Z","shell.execute_reply":"2022-11-28T19:47:41.703719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Total number of unique item ids: {df[\"item_id\"].nunique()}')\n\ndf_tmp = df[[\"item_id\",\"Sales_per_item\",\"item_cnt_day\"]]\ndf_tmp= pd.pivot_table(data=df_tmp,index=[\"item_id\"],aggfunc={\"item_cnt_day\":np.sum,\"Sales_per_item\":np.sum}).reset_index()\ndf_tmp_sales = df_tmp.sort_values(by=['Sales_per_item'],ascending=False).head(50).reset_index(drop=True)\ndf_tmp_count = df_tmp.sort_values(by=['item_cnt_day'],ascending=False).head(50).reset_index(drop=True)\n\nfig, axes = plt.subplots(2,1,figsize=(20,15))\nsns.barplot(x=df_tmp_count[\"item_id\"],y=df_tmp_count[\"item_cnt_day\"],ax=axes[0])\naxes[0].set_title(\"Top selling items of no of units sold\")\naxes[0].set_xticklabels(axes[0].get_xticklabels(),rotation=45)\nsns.barplot(x=df_tmp_sales[\"item_id\"],y=df_tmp_sales[\"Sales_per_item\"],ax=axes[1])\naxes[1].set_title('Top selling items in terms of Turn over')\naxes[1].set_xticklabels(axes[1].get_xticklabels(),rotation=45)\nplt.suptitle('Item id', fontsize=\"28\")\nplt.show()\n# del df_tmp,df_tmp_count,df_tmp_sales","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:47:41.705907Z","iopub.execute_input":"2022-11-28T19:47:41.706147Z","iopub.status.idle":"2022-11-28T19:47:43.545512Z","shell.execute_reply.started":"2022-11-28T19:47:41.706116Z","shell.execute_reply":"2022-11-28T19:47:43.544599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(f'Total number of unique item categorical ids: {df[\"item_category_id\"].nunique()}')  # doesn't work properly, commented out\nprint(f'Total number of unique item categorical ids: {df[\"category_id\"].nunique()}')  # <-- this is a code fix so the notebook can properly function\n\n#df_tmp = df[[\"item_category_id\",\"Sales_per_item\",\"item_cnt_day\"]]  df_tmp = df[[\"category_id\",\"Sales_per_item\",\"item_cnt_day\"]]\ndf_tmp = df[[\"category_id\",\"Sales_per_item\",\"item_cnt_day\"]]   # <-- this is a code fix so the notebook can properly function\n\n#df_tmp= pd.pivot_table(data=df_tmp,index=[\"item_category_id\"],aggfunc={\"item_cnt_day\":np.sum,\"Sales_per_item\":np.sum}).reset_index()  # doesn't work properly, commented out\ndf_tmp= pd.pivot_table(data=df_tmp,index=[\"category_id\"],aggfunc={\"item_cnt_day\":np.sum,\"Sales_per_item\":np.sum}).reset_index()  # <-- this is a code fix so the notebook can properly function\ndf_tmp_sales = df_tmp.sort_values(by=['Sales_per_item'],ascending=False).head(50).reset_index(drop=True)\ndf_tmp_count = df_tmp.sort_values(by=['item_cnt_day'],ascending=False).head(50).reset_index(drop=True)\n\nfig, axes = plt.subplots(2,1,figsize=(20,15))\n#sns.barplot(x=df_tmp_count[\"item_category_id\"],y=df_tmp_count[\"item_cnt_day\"],ax=axes[0])  # doesn't work properly, commented out\nsns.barplot(x=df_tmp_count[\"category_id\"],y=df_tmp_count[\"item_cnt_day\"],ax=axes[0])  # <-- this is a code fix so the notebook can properly function\naxes[0].set_title(\"Top selling items of no of units sold\")\naxes[0].set_xticklabels(axes[0].get_xticklabels(),rotation=45)\n#sns.barplot(x=df_tmp_sales[\"item_category_id\"],y=df_tmp_sales[\"Sales_per_item\"],ax=axes[1])  # doesn't work properly, commented out\nsns.barplot(x=df_tmp_sales[\"category_id\"],y=df_tmp_sales[\"Sales_per_item\"],ax=axes[1])   # <-- this is a code fix so the notebook can properly function\naxes[1].set_title('Top selling items in terms of Turn over')\naxes[1].set_xticklabels(axes[1].get_xticklabels(),rotation=45)\nplt.suptitle('Item Categorical id', fontsize=\"28\")\nplt.show()\ndel df_tmp,df_tmp_count,df_tmp_sales","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:47:43.546888Z","iopub.execute_input":"2022-11-28T19:47:43.547135Z","iopub.status.idle":"2022-11-28T19:47:45.065745Z","shell.execute_reply.started":"2022-11-28T19:47:43.547104Z","shell.execute_reply":"2022-11-28T19:47:45.065034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#item_categories = df['item_category_id'].unique()   # doesn't work properly, commented out\nitem_categories = df['category_id'].unique()   # <-- this is a code fix so the notebook can properly function\n\n#tmp = df[['item_id','item_category_id']].groupby(by=\"item_id\").nunique().reset_index()\ntmp = df[['item_id','category_id']].groupby(by=\"item_id\").nunique().reset_index()\ntmp.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:47:45.066986Z","iopub.execute_input":"2022-11-28T19:47:45.067987Z","iopub.status.idle":"2022-11-28T19:47:46.023759Z","shell.execute_reply.started":"2022-11-28T19:47:45.067942Z","shell.execute_reply":"2022-11-28T19:47:46.022752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"Year\"] = df[\"date\"].dt.year\ndf[\"Month\"] = df[\"date\"].dt.month\ndf[\"day_of_month\"] = df[\"date\"].dt.day\ndf[\"day_of_week\"] = df[\"date\"].dt.day_of_week","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:47:46.025018Z","iopub.execute_input":"2022-11-28T19:47:46.025414Z","iopub.status.idle":"2022-11-28T19:47:47.118558Z","shell.execute_reply.started":"2022-11-28T19:47:46.025379Z","shell.execute_reply":"2022-11-28T19:47:47.117567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,axes = plt.subplots(2,1,figsize=(25,12))\ndf_tmp = df[['date_block_num','Month','Sales_per_item']].groupby(by=['date_block_num']).aggregate(\"sum\").reset_index()\nsns.lineplot(x=df_tmp['date_block_num'],y=df_tmp['Sales_per_item'],ax=axes[0])\naxes[0].set_title('Total turn over (Total Sales)',fontsize=\"25\")\naxes[0].set_xlabel('Date',fontsize=\"20\")\naxes[0].set_ylabel('Turn over per month',fontsize=\"20\")\n\n\ndf_tmp = df[['date_block_num','Month','item_cnt_day']].groupby(by=['date_block_num']).aggregate(\"sum\").reset_index()\nsns.lineplot(x=df_tmp['date_block_num'],y=df_tmp['item_cnt_day'],ax=axes[1])\naxes[1].set_title('Total units sold',fontsize=\"25\")\naxes[1].set_xlabel('Date',fontsize=\"20\")\naxes[1].set_ylabel('Turn over per month',fontsize=\"20\")\n\nplt.tight_layout()\ndel df_tmp\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:47:47.120304Z","iopub.execute_input":"2022-11-28T19:47:47.120624Z","iopub.status.idle":"2022-11-28T19:47:48.102885Z","shell.execute_reply.started":"2022-11-28T19:47:47.120578Z","shell.execute_reply":"2022-11-28T19:47:48.101969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,axes = plt.subplots(1,2,figsize=(25,8))\ndf_tmp = df[['Year','Month','Sales_per_item']].pivot_table(index=['Month'],columns=['Year'],aggfunc={\"Sales_per_item\":np.sum})\naxes[0].plot(df_tmp)\naxes[0].set_title('Total turn over (Total Sales)')\naxes[0].legend(labels=[i[1] for i in df_tmp.columns])\n\ndf_tmp = df[['Year','Month','item_cnt_day']].pivot_table(index=['Month'],columns=['Year'],aggfunc={\"item_cnt_day\":np.sum})\naxes[1].plot(df_tmp)\naxes[1].set_title('Total no of units sold')\naxes[1].legend(labels=[i[1] for i in df_tmp.columns])\nplt.suptitle('Monthly Sales - Yearly',fontsize=\"28\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:47:48.104415Z","iopub.execute_input":"2022-11-28T19:47:48.104710Z","iopub.status.idle":"2022-11-28T19:47:48.879104Z","shell.execute_reply.started":"2022-11-28T19:47:48.104668Z","shell.execute_reply":"2022-11-28T19:47:48.878384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tmp = df[['date_block_num','shop_id','item_cnt_day']]\ndf_tmp.groupby(by='date_block_num').aggregate({'shop_id':'nunique'}).reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:47:48.880493Z","iopub.execute_input":"2022-11-28T19:47:48.880917Z","iopub.status.idle":"2022-11-28T19:47:49.378957Z","shell.execute_reply.started":"2022-11-28T19:47:48.880884Z","shell.execute_reply":"2022-11-28T19:47:49.378061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_tmp = df[['date_block_num','shop_id','item_cnt_day']]\ndt = pd.pivot_table(index='date_block_num',data=df_tmp,columns='shop_id',aggfunc=\"sum\").reset_index(drop=True)\ndt = dt.item_cnt_day\ndt.columns.name = 'Month'\ndt","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:47:49.380145Z","iopub.execute_input":"2022-11-28T19:47:49.380387Z","iopub.status.idle":"2022-11-28T19:47:49.614080Z","shell.execute_reply.started":"2022-11-28T19:47:49.380358Z","shell.execute_reply":"2022-11-28T19:47:49.612985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_outliers(df):\n    #remove outliers from item_cnt_day\n    df = df[df['item_cnt_day'] >= 0]\n    upper_quantile = df['item_cnt_day'].quantile(0.95)\n    df['item_cnt_day'] = np.where(df['item_cnt_day'] > upper_quantile, upper_quantile, df['item_cnt_day'])\n    \n    df = df[df['item_price'] >= 0]\n    upper_quantile = df['item_price'].quantile(0.95)\n    df['item_price'] = np.where(df['item_price'] > upper_quantile, upper_quantile, df['item_price'])\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:47:49.615446Z","iopub.execute_input":"2022-11-28T19:47:49.615802Z","iopub.status.idle":"2022-11-28T19:47:49.623099Z","shell.execute_reply.started":"2022-11-28T19:47:49.615755Z","shell.execute_reply":"2022-11-28T19:47:49.622128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load the merged data\ndf_train = pd.read_csv('merged_original.csv')\ndf_test = pd.read_csv('../input/english-converted-datasets/test.csv') # <-- this is a code fix so the notebook can properly function\nprint(df_train.shape,df_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:47:49.624757Z","iopub.execute_input":"2022-11-28T19:47:49.625204Z","iopub.status.idle":"2022-11-28T19:47:51.887048Z","shell.execute_reply.started":"2022-11-28T19:47:49.625134Z","shell.execute_reply":"2022-11-28T19:47:51.885866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#removing outliers as per our analysis\ndf_train = remove_outliers(df_train)\ndf_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:47:51.888185Z","iopub.execute_input":"2022-11-28T19:47:51.888405Z","iopub.status.idle":"2022-11-28T19:47:52.457659Z","shell.execute_reply.started":"2022-11-28T19:47:51.888379Z","shell.execute_reply":"2022-11-28T19:47:52.456679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['item_cnt_day'] = df_train['item_cnt_day'].clip(0,20)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:47:52.459077Z","iopub.execute_input":"2022-11-28T19:47:52.459442Z","iopub.status.idle":"2022-11-28T19:47:52.500137Z","shell.execute_reply.started":"2022-11-28T19:47:52.459392Z","shell.execute_reply":"2022-11-28T19:47:52.499332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from itertools import product\nts = time.time()\nmatrix = []\ncols = ['date_block_num','shop_id','item_id']\n\nfor i in range(34):\n    \n    # for each month, we are appending all month,shop_id,item_id combinations\n    sales = df_train[df_train['date_block_num']==i]\n    matrix.append(np.array(list(product([i], sales.shop_id.unique(), sales.item_id.unique())), dtype='int16'))\n        \n# creating a dataframe from list\nmatrix = pd.DataFrame(np.vstack(matrix), columns=cols)\n# convert to np.int8 to reduce memory usage\nmatrix['date_block_num'] = matrix['date_block_num'].astype(np.int8)\nmatrix['shop_id'] = matrix['shop_id'].astype(np.int8)\nmatrix['item_id'] = matrix['item_id'].astype(np.int16)\nmatrix.sort_values(cols,inplace=True)\nmatrix = matrix.reset_index(drop=True)\nprint(f'{time.time() - ts}')","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:47:52.501663Z","iopub.execute_input":"2022-11-28T19:47:52.501992Z","iopub.status.idle":"2022-11-28T19:48:06.283457Z","shell.execute_reply.started":"2022-11-28T19:47:52.501949Z","shell.execute_reply":"2022-11-28T19:48:06.282574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(matrix.shape)\nmatrix.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:48:06.285199Z","iopub.execute_input":"2022-11-28T19:48:06.285851Z","iopub.status.idle":"2022-11-28T19:48:06.298110Z","shell.execute_reply.started":"2022-11-28T19:48:06.285807Z","shell.execute_reply":"2022-11-28T19:48:06.297050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_test = df_test.drop(columns=['ID'])\n# assigning month variable\ndf_test['date_block_num'] = 34\n\n# conacting with train matrix\nmatrix = pd.concat([matrix,df_test],axis=0).reset_index(drop=True)\n\nmatrix.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:48:06.299310Z","iopub.execute_input":"2022-11-28T19:48:06.300108Z","iopub.status.idle":"2022-11-28T19:48:06.913837Z","shell.execute_reply.started":"2022-11-28T19:48:06.300071Z","shell.execute_reply":"2022-11-28T19:48:06.912885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# example\ndf_train.loc[(df_train['date_block_num'] == 0) &  (df_train['shop_id'] == 0) & (df_train['item_id'] == 32)]","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:48:06.915233Z","iopub.execute_input":"2022-11-28T19:48:06.915524Z","iopub.status.idle":"2022-11-28T19:48:06.943168Z","shell.execute_reply.started":"2022-11-28T19:48:06.915493Z","shell.execute_reply":"2022-11-28T19:48:06.942185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = df_train[['date_block_num','shop_id','item_id','item_cnt_day']]\ntmp = tmp.groupby(by=['date_block_num','shop_id','item_id']).agg({'item_cnt_day':'sum'})\ntmp.columns = ['item_cnt_month']\ntmp = tmp.reset_index(drop=False)\ntmp.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:48:06.944314Z","iopub.execute_input":"2022-11-28T19:48:06.944541Z","iopub.status.idle":"2022-11-28T19:48:07.922715Z","shell.execute_reply.started":"2022-11-28T19:48:06.944514Z","shell.execute_reply":"2022-11-28T19:48:07.921653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merging with main frame\nmatrix = matrix.merge(tmp,on=['date_block_num','shop_id','item_id'],how='left')\nmatrix = matrix.fillna(0)\n\n#clip values of max items sold per month to 20\nmatrix['item_cnt_month'] = matrix['item_cnt_month'].clip(0,20)\ndel tmp","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:48:07.924182Z","iopub.execute_input":"2022-11-28T19:48:07.924418Z","iopub.status.idle":"2022-11-28T19:48:13.145239Z","shell.execute_reply.started":"2022-11-28T19:48:07.924391Z","shell.execute_reply":"2022-11-28T19:48:13.144358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matrix.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:48:13.146667Z","iopub.execute_input":"2022-11-28T19:48:13.146954Z","iopub.status.idle":"2022-11-28T19:48:13.158115Z","shell.execute_reply.started":"2022-11-28T19:48:13.146924Z","shell.execute_reply":"2022-11-28T19:48:13.157104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lag_feature(df, lags, col):\n    \"\"\"\n    creates a lag feature. eg: item_cnt_month corresponding to a shop_id item_id combination of previous month, \n    previous second month etc\n    \"\"\"\n    \n    tmp = df[['date_block_num','shop_id','item_id',col]]\n    for i in lags:\n        shifted = tmp.copy()\n        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n        shifted['date_block_num'] += i\n        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:48:13.159714Z","iopub.execute_input":"2022-11-28T19:48:13.160019Z","iopub.status.idle":"2022-11-28T19:48:13.174270Z","shell.execute_reply.started":"2022-11-28T19:48:13.159986Z","shell.execute_reply":"2022-11-28T19:48:13.173488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts = time.time()\nmatrix = lag_feature(matrix, [1,2,3,4,5,6,7,8,9,10,11,12], 'item_cnt_month')\n#fill missing values\nmatrix = matrix.fillna(0)\ntime.time() - ts","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:48:13.175758Z","iopub.execute_input":"2022-11-28T19:48:13.176601Z","iopub.status.idle":"2022-11-28T19:49:57.466369Z","shell.execute_reply.started":"2022-11-28T19:48:13.176559Z","shell.execute_reply":"2022-11-28T19:49:57.465508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feats = [i for i in matrix.columns if 'lag' in i] + ['shop_id','item_id','date_block_num','item_cnt_month']\n\ndata = matrix[feats]\n\ntrain_df = data.loc[(data['date_block_num'] > 11) & (data['date_block_num'] < 33)]\nval_df = data.loc[data['date_block_num'] == 33]\ntest_df = data.loc[data['date_block_num'] == 34]\n\nX_train = train_df.drop(columns=['shop_id','item_id','date_block_num','item_cnt_month'])\ny_train = train_df['item_cnt_month']\nX_val = val_df.drop(columns=['shop_id','item_id','date_block_num','item_cnt_month'])\ny_val = val_df['item_cnt_month']\nX_test = test_df.drop(columns=['shop_id','item_id','date_block_num','item_cnt_month'])\n\nprint(X_train.shape,y_train.shape)\nprint(X_val.shape,y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:49:57.467493Z","iopub.execute_input":"2022-11-28T19:49:57.467734Z","iopub.status.idle":"2022-11-28T19:49:59.097267Z","shell.execute_reply.started":"2022-11-28T19:49:57.467704Z","shell.execute_reply":"2022-11-28T19:49:59.096201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del data\ndel train_df\ndel val_df\ndel test_df","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:49:59.098656Z","iopub.execute_input":"2022-11-28T19:49:59.098971Z","iopub.status.idle":"2022-11-28T19:49:59.109165Z","shell.execute_reply.started":"2022-11-28T19:49:59.098935Z","shell.execute_reply":"2022-11-28T19:49:59.108126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:49:59.110497Z","iopub.execute_input":"2022-11-28T19:49:59.111399Z","iopub.status.idle":"2022-11-28T19:49:59.569165Z","shell.execute_reply.started":"2022-11-28T19:49:59.111359Z","shell.execute_reply":"2022-11-28T19:49:59.568452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First RandomForestRegressor Model\nmodel = RandomForestRegressor(random_state=42,max_depth=5,n_estimators=50,min_samples_split=4)\nmodel.fit(X_train,y_train)\ny_train_pred = model.predict(X_train)\ny_val_pred = model.predict(X_val)\ny_test_pred = model.predict(X_test)\n\ntrain_rmse = mean_squared_error(y_train,y_train_pred,squared=False)\nval_rmse = mean_squared_error(y_val,y_val_pred,squared=False)\n\nprint(f'Train rmse: {train_rmse}')\nprint(f'Val rmse: {val_rmse}')","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:49:59.570534Z","iopub.execute_input":"2022-11-28T19:49:59.571406Z","iopub.status.idle":"2022-11-28T19:54:15.626229Z","shell.execute_reply.started":"2022-11-28T19:49:59.571357Z","shell.execute_reply":"2022-11-28T19:54:15.625112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Second RandomForestRegressor Model\nmodel2 = RandomForestRegressor(random_state=65,max_depth=8,n_estimators=80,min_samples_split=8)\nmodel2.fit(X_train,y_train)\ny_train_pred = model2.predict(X_train)\ny_val_pred = model2.predict(X_val)\ny_test_pred = model2.predict(X_test)\n\ntrain_rmse2 = mean_squared_error(y_train,y_train_pred,squared=False)\nval_rmse2 = mean_squared_error(y_val,y_val_pred,squared=False)\n\nprint(f'Train rmse2: {train_rmse2}')\nprint(f'Val rmse2: {val_rmse2}')","metadata":{"execution":{"iopub.status.busy":"2022-11-28T19:54:15.627565Z","iopub.execute_input":"2022-11-28T19:54:15.627805Z","iopub.status.idle":"2022-11-28T20:03:53.915513Z","shell.execute_reply.started":"2022-11-28T19:54:15.627779Z","shell.execute_reply":"2022-11-28T20:03:53.914582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_test = model.predict(X_test).clip(0, 20)\n#df_test = pd.read_csv('data/test.csv')\ndf_test = pd.read_csv('../input/english-converted-datasets/test.csv')  # <-- this is a code fix so the notebook can properly function\n\nsubmission = pd.DataFrame({\n    \"ID\": df_test.index, \n     \"item_cnt_month\": Y_test\n })\nsubmission.to_csv('submission.csv', index=False)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T20:03:53.916784Z","iopub.execute_input":"2022-11-28T20:03:53.917021Z","iopub.status.idle":"2022-11-28T20:03:54.706683Z","shell.execute_reply.started":"2022-11-28T20:03:53.916990Z","shell.execute_reply":"2022-11-28T20:03:54.705657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# A/B model parameter selection and comparison.","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nts = time.time()\n\n# First model\n\nmodel = xgb.XGBRegressor(\n    max_depth=8,\n    n_estimators=1000,\n    min_child_weight=300, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.3,    \n    seed=42)\n\nmodel.fit(\n    X_train, \n    y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(X_train, y_train), (X_val, y_val)], \n    verbose=True, \n    early_stopping_rounds = 10)\n\ntime.time() - ts","metadata":{"execution":{"iopub.status.busy":"2022-11-28T20:03:54.707911Z","iopub.execute_input":"2022-11-28T20:03:54.708205Z","iopub.status.idle":"2022-11-28T20:05:56.989235Z","shell.execute_reply.started":"2022-11-28T20:03:54.708145Z","shell.execute_reply":"2022-11-28T20:05:56.988362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_test = model.predict(X_test).clip(0, 20)\ndf_test = pd.read_csv(TEST_CSV)\nsubmission = pd.DataFrame({\n    \"ID\": df_test.index, \n    \"item_cnt_month\": Y_test\n})\nsubmission.to_csv('submission_predict_1.csv', index=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T20:05:56.990517Z","iopub.execute_input":"2022-11-28T20:05:56.990803Z","iopub.status.idle":"2022-11-28T20:05:57.463462Z","shell.execute_reply.started":"2022-11-28T20:05:56.990764Z","shell.execute_reply":"2022-11-28T20:05:57.462668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb2\nts2 = time.time()\n\n# Second model\n\nmodel2 = xgb2.XGBRegressor(\n    max_depth=10,\n    n_estimators=1500,\n    min_child_weight=360, \n    colsample_bytree=0.9, \n    subsample=0.6, \n    eta=0.2,    \n    seed=67)\n\nmodel2.fit(\n    X_train, \n    y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(X_train, y_train), (X_val, y_val)], \n    verbose=True, \n    early_stopping_rounds = 15)\n\ntime.time() - ts","metadata":{"execution":{"iopub.status.busy":"2022-11-28T20:05:57.464725Z","iopub.execute_input":"2022-11-28T20:05:57.464933Z","iopub.status.idle":"2022-11-28T20:10:31.480948Z","shell.execute_reply.started":"2022-11-28T20:05:57.464908Z","shell.execute_reply":"2022-11-28T20:10:31.480218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_test = model2.predict(X_test).clip(0, 20)\ndf_test = pd.read_csv(TEST_CSV)\nsubmission = pd.DataFrame({\n    \"ID\": df_test.index, \n    \"item_cnt_month\": Y_test\n})\nsubmission.to_csv('submission_predict_2.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T20:10:31.481922Z","iopub.execute_input":"2022-11-28T20:10:31.482807Z","iopub.status.idle":"2022-11-28T20:10:32.012608Z","shell.execute_reply.started":"2022-11-28T20:10:31.482768Z","shell.execute_reply":"2022-11-28T20:10:32.011779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Any ideas for running a comparison between submission_predict_1 and submission_predict_2 would be appreciated.","metadata":{}}]}